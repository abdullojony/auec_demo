{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdullojony/auec_demo/blob/main/auec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "erZXjwTSh-OY"
      },
      "id": "erZXjwTSh-OY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7d359c5",
      "metadata": {
        "id": "a7d359c5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import umap\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.metrics import accuracy_score, normalized_mutual_info_score, adjusted_rand_score\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import mode\n",
        "import random\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIL9-h0f8UgQ",
        "outputId": "ed67417d-2e62-4e63-92bb-87870c420d99"
      },
      "id": "UIL9-h0f8UgQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c47fb4f",
      "metadata": {
        "id": "8c47fb4f"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67139bfa",
      "metadata": {
        "id": "67139bfa"
      },
      "outputs": [],
      "source": [
        "# --- Configuration ---\n",
        "\n",
        "CONFIG = {\n",
        "    # General settings\n",
        "    \"DEVICE\": 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    \"SEED\": 42,\n",
        "    \"MNIST_DIR\": \"./drive/MyDrive/data/mnist/\",  # Directory to store MNIST data\n",
        "    \"OUTPUT_DIR\": \"./drive/MyDrive/output/\",    # Directory to store all outputs (models, plots, data)\n",
        "    \"NUM_CLUSTERS\": 10,         # Number of clusters (digits for MNIST)\n",
        "\n",
        "    # Data loading\n",
        "    \"PRETRAIN_BATCH_SIZE\": 256,\n",
        "    \"TRAIN_BATCH_SIZE\": 256,\n",
        "    \"EVAL_BATCH_SIZE\": 60000, # For evaluating on the full dataset\n",
        "\n",
        "    # Pre-training CAE\n",
        "    \"PRETRAIN_EPOCHS\": 10,\n",
        "    \"PRETRAIN_LR\": 0.01,\n",
        "    \"PRETRAIN_WEIGHT_DECAY\": 1e-5,\n",
        "    \"PRETRAIN_KMEANS_INIT\": 'k-means++',\n",
        "\n",
        "    # Stage I: AUEC Training\n",
        "    \"AUEC_EPOCHS\": 10, # Original: 30\n",
        "    \"AUEC_LR\": 0.01,\n",
        "    \"AUEC_WEIGHT_DECAY\": 1e-5,\n",
        "    \"AUEC_RECONSTRUCTION_WEIGHT\": 1.0,\n",
        "    \"AUEC_SEPARABILITY_WEIGHT\": 0.0003,\n",
        "\n",
        "    # Stage II: UMAP\n",
        "    \"UMAP_N_NEIGHBORS\": 8,\n",
        "    \"UMAP_N_COMPONENTS\": 8,\n",
        "    \"UMAP_MIN_DIST\": 0.01,\n",
        "\n",
        "    # Stage III: Clustering\n",
        "    # K-Means specific\n",
        "    \"KMEANS_INIT\": 'k-means++',\n",
        "    # MDBSCAN specific\n",
        "    \"MDBSCAN_EPSILON\": 0.17,\n",
        "    \"MDBSCAN_MIN_SAMPLES\": 12,\n",
        "\n",
        "    # Plotting\n",
        "    \"PLOT_FIGURE_SIZE\": (10, 7),\n",
        "    \"PLOT_SCATTER_FIGURE_SIZE\": (8, 8),\n",
        "    \"PLOT_CMAP\": 'Spectral',\n",
        "    \"PLOT_SCATTER_S\": 5,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility Functions"
      ],
      "metadata": {
        "id": "vV75ue4-iskD"
      },
      "id": "vV75ue4-iskD"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Utility Functions ---\n",
        "\n",
        "def seed_everything(seed):\n",
        "    \"\"\"Seed everything to make the code more reproducible.\"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    print(f\"Seeded everything with seed {seed}\")\n",
        "\n",
        "def ensure_dir(directory_path):\n",
        "    \"\"\"Ensure that a directory exists, creating it if necessary.\"\"\"\n",
        "    if not os.path.exists(directory_path):\n",
        "        os.makedirs(directory_path)\n",
        "        print(f\"Created directory: {directory_path}\")"
      ],
      "metadata": {
        "id": "fpmQ6m9rixry"
      },
      "id": "fpmQ6m9rixry",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b0b7db33",
      "metadata": {
        "id": "b0b7db33"
      },
      "source": [
        "\n",
        "# Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9f246a3",
      "metadata": {
        "id": "c9f246a3"
      },
      "outputs": [],
      "source": [
        "# --- Loss Functions ---\n",
        "\n",
        "def update_assignments(enc_output, centroids):\n",
        "    \"\"\"\n",
        "    Assigns each data point to the closest centroid.\n",
        "    Args:\n",
        "        enc_output (torch.Tensor): Encoded output from the autoencoder.\n",
        "        centroids (torch.Tensor): Current cluster centroids.\n",
        "    Returns:\n",
        "        torch.Tensor: Cluster assignments for each data point.\n",
        "    \"\"\"\n",
        "    distances = torch.cdist(enc_output, centroids)\n",
        "    assignments = distances.argmin(dim=1)\n",
        "    return assignments\n",
        "\n",
        "def update_centroids(enc_output, assignments, num_clusters):\n",
        "    \"\"\"\n",
        "    Updates centroids based on the mean of assigned data points.\n",
        "    Args:\n",
        "        enc_output (torch.Tensor): Encoded output.\n",
        "        assignments (torch.Tensor): Cluster assignments.\n",
        "        num_clusters (int): Total number of clusters.\n",
        "    Returns:\n",
        "        torch.Tensor: Updated centroids.\n",
        "    \"\"\"\n",
        "    centroids = torch.zeros((num_clusters, enc_output.shape[1]), device=enc_output.device)\n",
        "    for k in range(num_clusters):\n",
        "        assigned_data = enc_output[assignments == k]\n",
        "        if assigned_data.size(0) > 0:\n",
        "            centroids[k] = assigned_data.mean(dim=0)\n",
        "    return centroids\n",
        "\n",
        "def wcss_loss(enc_output, assignments, centroids):\n",
        "    \"\"\"\n",
        "    Calculates the Within-Cluster Sum of Squares (WCSS).\n",
        "    Args:\n",
        "        enc_output (torch.Tensor): Encoded output.\n",
        "        assignments (torch.Tensor): Cluster assignments.\n",
        "        centroids (torch.Tensor): Cluster centroids.\n",
        "    Returns:\n",
        "        torch.Tensor: WCSS loss.\n",
        "    \"\"\"\n",
        "    device = enc_output.device\n",
        "\n",
        "    # Infer number of clusters from assignments\n",
        "    unique_assigned_clusters = torch.unique(assignments)\n",
        "\n",
        "    if centroids.shape[0] == 0 or unique_assigned_clusters.size(0) == 0:\n",
        "        # No centroids, no assignments\n",
        "        return torch.tensor(0.0, device=device)\n",
        "\n",
        "    total_wcss = 0.0\n",
        "    total_points = 0\n",
        "\n",
        "    for i_idx, cluster_idx_val in enumerate(unique_assigned_clusters):\n",
        "        # Convert cluster_idx_val to integer\n",
        "        k = cluster_idx_val.item()\n",
        "\n",
        "        cluster_points = enc_output[assignments == k]\n",
        "        if cluster_points.size(0) > 0:\n",
        "            centroid_k = centroids[k].to(device)\n",
        "            wcss_k = torch.sum((cluster_points - centroid_k)**2)\n",
        "            total_wcss += wcss_k\n",
        "            total_points += cluster_points.size(0)\n",
        "\n",
        "    return total_wcss / total_points"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03eb27ed",
      "metadata": {
        "id": "03eb27ed"
      },
      "source": [
        "# Convolutional Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7e75089",
      "metadata": {
        "id": "c7e75089"
      },
      "outputs": [],
      "source": [
        "# --- Convolutional Autoencoder Model ---\n",
        "\n",
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvAutoencoder, self).__init__()\n",
        "        # Input: 1x28x28\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3, stride=2, padding=1),  # Output: 8x14x14\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(8, 16, 3, stride=2, padding=1), # Output: 16x7x7\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1),# Output: 32x4x4\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(32, 64, 4, stride=1, padding=0), # Output: 64x1x1\n",
        "            nn.ReLU(True),\n",
        "            nn.Flatten(),  # Output: 64\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Unflatten(1, (64, 1, 1)), # Input: 64 -> Output: 64x1x1\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=1, padding=0), # Output: 32x4x4\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, 16, 2, stride=2, padding=1, output_padding=1), # Output: 16x7x7\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1), # Output: 8x14x14\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(8, 1, 3, stride=2,  padding=1, output_padding=1), # Output: 1x28x28\n",
        "            nn.Sigmoid() # Using Sigmoid for image pixel values (0-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46347963",
      "metadata": {
        "id": "46347963"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b4d28ab",
      "metadata": {
        "id": "5b4d28ab"
      },
      "outputs": [],
      "source": [
        "# --- Data Loading ---\n",
        "\n",
        "def get_mnist_dataloaders(config):\n",
        "    \"\"\"Loads MNIST dataset and returns dataloaders.\"\"\"\n",
        "    transform = transforms.ToTensor() # MNIST images are 0-1\n",
        "    train_dataset = MNIST(config[\"MNIST_DIR\"], train=True, download=True, transform=transform)\n",
        "    test_dataset = MNIST(config[\"MNIST_DIR\"], train=False, download=True, transform=transform)\n",
        "\n",
        "    train_dl = DataLoader(train_dataset, batch_size=config[\"PRETRAIN_BATCH_SIZE\"], shuffle=True) # Shuffle for pretraining\n",
        "    train_dl_auec = DataLoader(train_dataset, batch_size=config[\"TRAIN_BATCH_SIZE\"], shuffle=True) # Shuffle for AUEC\n",
        "\n",
        "    # Dataloader for full dataset evaluation/embedding extraction\n",
        "    full_train_dl = DataLoader(train_dataset, batch_size=config[\"EVAL_BATCH_SIZE\"], shuffle=False)\n",
        "\n",
        "    print(f\"MNIST training data: {len(train_dataset)} samples\")\n",
        "    print(f\"MNIST test data: {len(test_dataset)} samples\")\n",
        "    return train_dl, train_dl_auec, full_train_dl, train_dataset.targets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e96748f6",
      "metadata": {
        "id": "e96748f6"
      },
      "source": [
        "# Pre-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd68747",
      "metadata": {
        "id": "bfd68747"
      },
      "outputs": [],
      "source": [
        "# --- Pre-training Stage ---\n",
        "\n",
        "def pretrain_cae(model, train_dl, config, device):\n",
        "    \"\"\"Pre-trains the Convolutional Autoencoder.\"\"\"\n",
        "    print(\"\\n--- Starting CAE Pre-training ---\")\n",
        "    output_dir = config[\"OUTPUT_DIR\"]\n",
        "\n",
        "    model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"PRETRAIN_LR\"], weight_decay=config[\"PRETRAIN_WEIGHT_DECAY\"])\n",
        "\n",
        "    losses_pre = []\n",
        "    for epoch in range(1, config[\"PRETRAIN_EPOCHS\"] + 1):\n",
        "        model.train()\n",
        "        train_loss_pre = 0.0\n",
        "        encoded_list_epoch = []\n",
        "\n",
        "        for images, _ in train_dl:\n",
        "            images = images.to(device)\n",
        "            encoded, decoded = model(images)\n",
        "            loss = criterion(decoded, images)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss_pre += loss.item() * images.size(0)\n",
        "            if epoch == config[\"PRETRAIN_EPOCHS\"]: # Save encoded data from the last epoch\n",
        "                encoded_list_epoch.append(encoded.detach().cpu().numpy())\n",
        "\n",
        "        train_loss_pre /= len(train_dl.dataset) # Average loss per sample\n",
        "        losses_pre.append(train_loss_pre)\n",
        "        print(f'Pre-train Epoch: {epoch}/{config[\"PRETRAIN_EPOCHS\"]}\\tTraining Loss: {train_loss_pre:.6f}')\n",
        "\n",
        "    # Save pre-trained model weights\n",
        "    pretrain_model_path = os.path.join(output_dir, f\"CAE_Pretrained_Epochs{config['PRETRAIN_EPOCHS']}_LR{config['PRETRAIN_LR']}.pth\")\n",
        "    torch.save(model.state_dict(), pretrain_model_path)\n",
        "    print(f\"Saved pre-trained model to {pretrain_model_path}\")\n",
        "\n",
        "    # Concatenate all encoded outputs from the last epoch\n",
        "    encoded_data_full = np.concatenate(encoded_list_epoch, axis=0)\n",
        "\n",
        "    # Apply KMeans to the encoded data to get initial centroids\n",
        "    print(\"Applying KMeans to pre-trained embeddings for initial centroids...\")\n",
        "    kmeans = KMeans(n_clusters=config[\"NUM_CLUSTERS\"], init=config[\"PRETRAIN_KMEANS_INIT\"], n_init=10, random_state=config[\"SEED\"])\n",
        "    kmeans.fit(encoded_data_full)\n",
        "\n",
        "    initial_centroids = torch.from_numpy(kmeans.cluster_centers_).float().to(device)\n",
        "    initial_labels = kmeans.labels_\n",
        "\n",
        "    # Save initial centroids and labels\n",
        "    centroids_path = os.path.join(output_dir, f\"InitialCentroids_KMeans.npy\")\n",
        "    labels_path = os.path.join(output_dir, f\"InitialLabels_KMeans.npy\")\n",
        "    np.save(centroids_path, initial_centroids.cpu().numpy())\n",
        "    np.save(labels_path, initial_labels)\n",
        "    print(f\"Saved initial K-Means centroids to {centroids_path}\")\n",
        "\n",
        "    return initial_centroids, pretrain_model_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7964c79c",
      "metadata": {
        "id": "7964c79c"
      },
      "source": [
        "# Stage I: Training of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67cbc22d",
      "metadata": {
        "id": "67cbc22d"
      },
      "outputs": [],
      "source": [
        "# --- Stage I: AUEC Training ---\n",
        "\n",
        "def train_auec(model, train_dl_auec, initial_centroids, config, device, pretrained_model_path=None):\n",
        "    \"\"\"Trains the model with AUEC loss (Reconstruction + WCSS).\"\"\"\n",
        "    print(\"\\n--- Starting AUEC Training (Stage I) ---\")\n",
        "    output_dir = config[\"OUTPUT_DIR\"]\n",
        "\n",
        "    if pretrained_model_path:\n",
        "        print(f\"Loading pre-trained weights from: {pretrained_model_path}\")\n",
        "        model.load_state_dict(torch.load(pretrained_model_path, map_location=device))\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"AUEC_LR\"], weight_decay=config[\"AUEC_WEIGHT_DECAY\"])\n",
        "    reconstruction_criterion = nn.MSELoss()\n",
        "\n",
        "    centroids = initial_centroids.clone().to(device)\n",
        "\n",
        "    losses_r_auec = []\n",
        "    losses_c_auec = []\n",
        "    losses_total_auec = []\n",
        "\n",
        "    for epoch in range(1, config[\"AUEC_EPOCHS\"] + 1):\n",
        "        model.train()\n",
        "        total_loss_r = 0\n",
        "        total_loss_c = 0\n",
        "        total_loss = 0\n",
        "\n",
        "        for images, _ in train_dl_auec:\n",
        "            images = images.to(device)\n",
        "            enc_auec, dec_auec = model(images)\n",
        "\n",
        "            # Reconstruction loss\n",
        "            loss_r = config[\"AUEC_RECONSTRUCTION_WEIGHT\"] * reconstruction_criterion(dec_auec, images)\n",
        "\n",
        "            # Update assignments (non-differentiable part for WCSS calculation)\n",
        "            with torch.no_grad(): # Assignments should not affect encoder's gradients directly here\n",
        "                assignments = update_assignments(enc_auec.detach(), centroids) # Use detached enc_auec for assignment\n",
        "\n",
        "            # Clustering loss (WCSS)\n",
        "            # WCSS needs enc_auec (not detached) to flow gradients back to encoder\n",
        "            loss_c = config[\"AUEC_SEPARABILITY_WEIGHT\"] * wcss_loss(enc_auec, assignments, centroids)\n",
        "\n",
        "            # Total loss\n",
        "            current_total_loss = loss_r + loss_c\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            current_total_loss.backward() # Gradients flow from both reconstruction and WCSS(via enc_auec)\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update centroids (non-differentiable SGD-like step)\n",
        "            with torch.no_grad():\n",
        "                 centroids = update_centroids(enc_auec.detach(), assignments, config[\"NUM_CLUSTERS\"])\n",
        "\n",
        "            total_loss_r += loss_r.item() * images.size(0)\n",
        "            total_loss_c += loss_c.item() * images.size(0)\n",
        "            total_loss += current_total_loss.item() * images.size(0)\n",
        "\n",
        "        avg_loss_r = total_loss_r / len(train_dl_auec.dataset)\n",
        "        avg_loss_c = total_loss_c / len(train_dl_auec.dataset)\n",
        "        avg_total_loss = total_loss / len(train_dl_auec.dataset)\n",
        "\n",
        "        losses_r_auec.append(avg_loss_r)\n",
        "        losses_c_auec.append(avg_loss_c)\n",
        "        losses_total_auec.append(avg_total_loss)\n",
        "\n",
        "        print(f'AUEC Epoch: {epoch}/{config[\"AUEC_EPOCHS\"]} \\t'\n",
        "              f'Total Loss: {avg_total_loss:.6f} \\t'\n",
        "              f'Recon Loss: {avg_loss_r:.6f} \\t'\n",
        "              f'Cluster Loss: {avg_loss_c:.6f}')\n",
        "\n",
        "    # Plot loss curve\n",
        "    plt.figure(figsize=config[\"PLOT_FIGURE_SIZE\"])\n",
        "    plt.plot(losses_r_auec, label='Reconstruction Loss')\n",
        "    plt.plot(losses_c_auec, label='Clustering (WCSS) Loss')\n",
        "    plt.plot(losses_total_auec, label='Total Loss')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"AUEC Training Loss Curves\")\n",
        "    plt.legend()\n",
        "    loss_curve_path = os.path.join(output_dir, f\"AUEC_LossCurve_Epochs{config['AUEC_EPOCHS']}_RW{config['AUEC_RECONSTRUCTION_WEIGHT']}_SW{config['AUEC_SEPARABILITY_WEIGHT']}.png\")\n",
        "    plt.savefig(loss_curve_path)\n",
        "    plt.close()\n",
        "    print(f\"Saved AUEC loss curve to {loss_curve_path}\")\n",
        "\n",
        "    # Save the final AUEC model\n",
        "    auec_model_path = os.path.join(output_dir, f\"AUEC_Model_Final_Epochs{config['AUEC_EPOCHS']}.pth\")\n",
        "    torch.save(model.state_dict(), auec_model_path)\n",
        "    print(f\"Saved final AUEC model to {auec_model_path}\")\n",
        "\n",
        "    return auec_model_path, centroids # Return final centroids as well\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "797e4158",
      "metadata": {
        "id": "797e4158"
      },
      "source": [
        "# Evaluation and Embedding Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c60bdd06",
      "metadata": {
        "id": "c60bdd06"
      },
      "outputs": [],
      "source": [
        "# --- Evaluation and Embedding Extraction ---\n",
        "\n",
        "def get_embeddings(model, full_train_dl, config, device, model_path=None):\n",
        "    \"\"\"Extracts embeddings from the trained model for the full training dataset.\"\"\"\n",
        "    print(\"\\n--- Extracting Embeddings ---\")\n",
        "    output_dir = config[\"OUTPUT_DIR\"]\n",
        "\n",
        "    if model_path:\n",
        "        print(f\"Loading model for embedding extraction from: {model_path}\")\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for images, _ in full_train_dl: # Use the full dataset loader\n",
        "            images = images.to(device)\n",
        "            enc, _ = model(images)\n",
        "            all_embeddings.append(enc.cpu().numpy())\n",
        "\n",
        "    compressed_embedding = np.concatenate(all_embeddings, axis=0)\n",
        "    embedding_path = os.path.join(output_dir, \"AUEC_CompressedEmbeddings.npy\")\n",
        "    np.save(embedding_path, compressed_embedding)\n",
        "    print(f\"Saved compressed embeddings ({compressed_embedding.shape}) to {embedding_path}\")\n",
        "    return compressed_embedding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e9a6078",
      "metadata": {
        "id": "1e9a6078"
      },
      "source": [
        "# Stage II: UMAP\n",
        "**we set UMAP number of components to $n_C = 2$ for the ease of visualization, and we also take $n_N = 8$.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea1b42b",
      "metadata": {
        "id": "0ea1b42b"
      },
      "outputs": [],
      "source": [
        "# --- Stage II: UMAP ---\n",
        "\n",
        "def apply_umap(embeddings, config):\n",
        "    \"\"\"Applies UMAP to the embeddings.\"\"\"\n",
        "    print(\"\\n--- Applying UMAP (Stage II) ---\")\n",
        "    output_dir = config[\"OUTPUT_DIR\"]\n",
        "\n",
        "    reducer = umap.UMAP(\n",
        "        n_neighbors=config[\"UMAP_N_NEIGHBORS\"],\n",
        "        n_components=config[\"UMAP_N_COMPONENTS\"],\n",
        "        min_dist=config[\"UMAP_MIN_DIST\"],\n",
        "        random_state=config[\"SEED\"],\n",
        "        metric='euclidean' # common metric for image embeddings\n",
        "    )\n",
        "    refined_embedding = reducer.fit_transform(embeddings)\n",
        "\n",
        "    umap_path = os.path.join(output_dir, f\"UMAP_RefinedEmbeddings_NComp{config['UMAP_N_COMPONENTS']}_NNeigh{config['UMAP_N_NEIGHBORS']}.npy\")\n",
        "    np.save(umap_path, refined_embedding)\n",
        "    print(f\"Saved UMAP refined embeddings ({refined_embedding.shape}) to {umap_path}\")\n",
        "    return refined_embedding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f678b74f",
      "metadata": {
        "id": "f678b74f"
      },
      "source": [
        "# Stage III: Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5423e47",
      "metadata": {
        "id": "d5423e47"
      },
      "outputs": [],
      "source": [
        "# --- Stage III: Clustering ---\n",
        "\n",
        "def map_cluster_labels_to_true(y_pred_cluster, y_true):\n",
        "    \"\"\"Maps cluster labels to true labels based on majority voting.\"\"\"\n",
        "    mapped_labels = np.zeros_like(y_pred_cluster)\n",
        "    unique_pred_labels = np.unique(y_pred_cluster)\n",
        "\n",
        "    for cluster_id in unique_pred_labels:\n",
        "        mask = (y_pred_cluster == cluster_id)\n",
        "        true_labels_in_cluster = y_true[mask]\n",
        "\n",
        "        if len(true_labels_in_cluster) == 0:\n",
        "            # This case should ideally not happen if cluster_id comes from unique_pred_labels\n",
        "            # and y_pred_cluster has same length as y_true.\n",
        "            # Assign a placeholder or handle as an error/warning.\n",
        "            # For MNIST, labels are 0-9. -1 can be a noise/unassigned placeholder.\n",
        "            mapped_label = -1 # Or a label that's out of the typical range.\n",
        "        else:\n",
        "            mapped_label = mode(true_labels_in_cluster, keepdims=True)[0][0]\n",
        "        mapped_labels[mask] = mapped_label\n",
        "    return mapped_labels\n",
        "\n",
        "def plot_embedding_space(embedding_2d, labels, title, filepath, config):\n",
        "    \"\"\"Plots 2D embedding space.\"\"\"\n",
        "    plt.figure(figsize=config[\"PLOT_SCATTER_FIGURE_SIZE\"])\n",
        "    scatter = plt.scatter(embedding_2d[:, 0], embedding_2d[:, 1], c=labels, cmap=config[\"PLOT_CMAP\"], s=config[\"PLOT_SCATTER_S\"])\n",
        "    plt.gca().set_aspect('equal', 'datalim')\n",
        "    plt.colorbar(scatter, boundaries=np.arange(config[\"NUM_CLUSTERS\"] + 1) - 0.5).set_ticks(np.arange(config[\"NUM_CLUSTERS\"]))\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.xlabel(\"UMAP Component 1\")\n",
        "    plt.ylabel(\"UMAP Component 2\")\n",
        "    plt.savefig(filepath)\n",
        "    plt.close()\n",
        "    print(f\"Saved plot: {filepath}\")\n",
        "\n",
        "def evaluate_clustering(y_true, y_pred_mapped, algorithm_name):\n",
        "    \"\"\"Calculates and prints clustering metrics.\"\"\"\n",
        "    # Filter out any points that were mapped to -1 (e.g. noise or unassigned in mapping step)\n",
        "    # if this is a possibility from map_cluster_labels_to_true\n",
        "    valid_indices = y_pred_mapped != -1\n",
        "    if not np.all(valid_indices): # If there are any -1 labels\n",
        "        print(f\"Note: Evaluating {algorithm_name} on {np.sum(valid_indices)}/{len(y_true)} points (excluding unmapped labels).\")\n",
        "\n",
        "    y_true_eval = y_true[valid_indices]\n",
        "    y_pred_mapped_eval = y_pred_mapped[valid_indices]\n",
        "\n",
        "    if len(y_true_eval) == 0: # No points to evaluate\n",
        "        print(f\"{algorithm_name}: No valid points for evaluation.\")\n",
        "        return {\"ACC\": 0, \"NMI\": 0, \"ARI\": 0}\n",
        "\n",
        "    acc = accuracy_score(y_true_eval, y_pred_mapped_eval)\n",
        "    nmi = normalized_mutual_info_score(y_true_eval, y_pred_mapped_eval)\n",
        "    ari = adjusted_rand_score(y_true_eval, y_pred_mapped_eval)\n",
        "\n",
        "    print(f\"\\n--- {algorithm_name} Clustering Results ---\")\n",
        "    print(f\"Accuracy (ACC): {acc:.4f}\")\n",
        "    print(f\"Normalized Mutual Information (NMI): {nmi:.4f}\")\n",
        "    print(f\"Adjusted Rand Index (ARI): {ari:.4f}\")\n",
        "    return {\"ACC\": acc, \"NMI\": nmi, \"ARI\": ari}\n",
        "\n",
        "def run_kmeans_clustering(refined_embedding, y_true, config):\n",
        "    \"\"\"Runs K-Means clustering and evaluates.\"\"\"\n",
        "    print(\"\\n--- Running K-Means Clustering (Stage III) ---\")\n",
        "    output_dir = config[\"OUTPUT_DIR\"]\n",
        "\n",
        "    kmeans = KMeans(\n",
        "        n_clusters=config[\"NUM_CLUSTERS\"],\n",
        "        init=config[\"KMEANS_INIT\"],\n",
        "        n_init=10, # Standard value for k-means++\n",
        "        random_state=config[\"SEED\"]\n",
        "    )\n",
        "    y_pred_kmeans_raw = kmeans.fit_predict(refined_embedding)\n",
        "    y_pred_kmeans_mapped = map_cluster_labels_to_true(y_pred_kmeans_raw, y_true)\n",
        "\n",
        "    # Save mapped labels\n",
        "    kmeans_labels_path = os.path.join(output_dir, \"KMeans_PredictedLabels_Mapped.npy\")\n",
        "    np.save(kmeans_labels_path, y_pred_kmeans_mapped)\n",
        "    print(f\"Saved K-Means mapped predicted labels to {kmeans_labels_path}\")\n",
        "\n",
        "    # Plotting (if 2D)\n",
        "    if refined_embedding.shape[1] == 2:\n",
        "        plot_path = os.path.join(output_dir, \"KMeans_UMAP_Plot.png\")\n",
        "        plot_embedding_space(refined_embedding, y_pred_kmeans_mapped, \"K-Means Clustering on UMAP Embedding\", plot_path, config)\n",
        "\n",
        "    return evaluate_clustering(y_true, y_pred_kmeans_mapped, \"K-Means\")\n",
        "\n",
        "\n",
        "def run_mdbscan_clustering(refined_embedding, y_true, config):\n",
        "    \"\"\"Runs modified DBSCAN clustering and evaluates.\"\"\"\n",
        "    print(\"\\n--- Running MDBSCAN Clustering (Stage III) ---\")\n",
        "    output_dir = config[\"OUTPUT_DIR\"]\n",
        "\n",
        "    dbscan = DBSCAN(eps=config[\"MDBSCAN_EPSILON\"], min_samples=config[\"MDBSCAN_MIN_SAMPLES\"])\n",
        "    y_pred_dbscan_raw = dbscan.fit_predict(refined_embedding)\n",
        "\n",
        "    print(f\"DBSCAN initial clusters found: {Counter(y_pred_dbscan_raw)}\")\n",
        "\n",
        "    # MDBSCAN modification: Reassign outliers and small clusters\n",
        "    cluster_counts = Counter(y_pred_dbscan_raw)\n",
        "    valid_clusters = {k: v for k, v in cluster_counts.items() if k != -1} # Exclude noise points\n",
        "\n",
        "    y_pred_mdbscan_reassigned = np.copy(y_pred_dbscan_raw) # Start with raw predictions\n",
        "\n",
        "    if not valid_clusters:\n",
        "        print(\"MDBSCAN: No valid non-noise clusters found by DBSCAN. Mapping raw DBSCAN output (including noise).\")\n",
        "        # No reassignment possible if no valid clusters to form centroids\n",
        "    else:\n",
        "        num_top_clusters = min(config[\"NUM_CLUSTERS\"], len(valid_clusters))\n",
        "        largest_cluster_ids = [item[0] for item in sorted(valid_clusters.items(), key=lambda x: x[1], reverse=True)[:num_top_clusters]]\n",
        "\n",
        "        print(f\"MDBSCAN: Top {len(largest_cluster_ids)} largest non-noise clusters selected: {largest_cluster_ids}\")\n",
        "\n",
        "        mdbscan_centroids_list = []\n",
        "        valid_largest_cluster_ids_for_reassignment = [] # Store IDs of clusters for which centroids could be made\n",
        "\n",
        "        for cluster_id in largest_cluster_ids:\n",
        "            cluster_points = refined_embedding[y_pred_dbscan_raw == cluster_id]\n",
        "            if cluster_points.shape[0] > 0:\n",
        "                 mdbscan_centroids_list.append(np.mean(cluster_points, axis=0))\n",
        "                 valid_largest_cluster_ids_for_reassignment.append(cluster_id)\n",
        "            # else: Should not happen if cluster_id came from Counter based on y_pred_dbscan_raw\n",
        "\n",
        "        if not mdbscan_centroids_list: # No centroids could be computed\n",
        "            print(\"MDBSCAN: No centroids for reassignment (e.g. selected largest clusters were empty, though unlikely). Mapping raw DBSCAN output.\")\n",
        "        else:\n",
        "            mdbscan_centroids_np = np.array(mdbscan_centroids_list)\n",
        "            # Reassign points that are noise (-1) or not in one of the `valid_largest_cluster_ids_for_reassignment`\n",
        "            for i, point_label in enumerate(y_pred_dbscan_raw):\n",
        "                if point_label == -1 or point_label not in valid_largest_cluster_ids_for_reassignment:\n",
        "                    point = refined_embedding[i]\n",
        "                    distances = [np.linalg.norm(point - centroid) for centroid in mdbscan_centroids_np]\n",
        "                    if distances:\n",
        "                        nearest_centroid_idx = np.argmin(distances)\n",
        "                        y_pred_mdbscan_reassigned[i] = valid_largest_cluster_ids_for_reassignment[nearest_centroid_idx]\n",
        "\n",
        "    # Map the (potentially reassigned) labels to true labels\n",
        "    y_pred_mdbscan_mapped = map_cluster_labels_to_true(y_pred_mdbscan_reassigned, y_true)\n",
        "\n",
        "\n",
        "    # Save mapped labels\n",
        "    mdbscan_labels_path = os.path.join(output_dir, \"MDBSCAN_PredictedLabels_Mapped.npy\")\n",
        "    np.save(mdbscan_labels_path, y_pred_mdbscan_mapped)\n",
        "    print(f\"Saved MDBSCAN mapped predicted labels to {mdbscan_labels_path}\")\n",
        "\n",
        "    # Plotting (if 2D)\n",
        "    if refined_embedding.shape[1] == 2:\n",
        "        plot_path = os.path.join(output_dir, \"MDBSCAN_UMAP_Plot.png\")\n",
        "        plot_embedding_space(refined_embedding, y_pred_mdbscan_mapped, \"MDBSCAN Clustering on UMAP Embedding\", plot_path, config)\n",
        "\n",
        "    return evaluate_clustering(y_true, y_pred_mdbscan_mapped, \"MDBSCAN\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution"
      ],
      "metadata": {
        "id": "1I_-1Qp2k_IF"
      },
      "id": "1I_-1Qp2k_IF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply seed and create output directory\n",
        "seed_everything(CONFIG[\"SEED\"])\n",
        "ensure_dir(CONFIG[\"OUTPUT_DIR\"])\n",
        "print(f\"Using device: {CONFIG['DEVICE']}\")\n",
        "\n",
        "# 1. Load Data\n",
        "# Using separate Dataloaders for pretraining and AUEC training to allow different batch sizes/shuffling\n",
        "train_dl_pretrain, train_dl_auec, full_train_dl, train_true_labels = get_mnist_dataloaders(CONFIG)\n",
        "train_true_labels = train_true_labels.numpy() # For evaluation\n",
        "\n",
        "# 2. Initialize Model\n",
        "cae_model = ConvAutoencoder()\n",
        "\n",
        "# 3. Pre-training\n",
        "# Set to True to run pre-training, False to load pre-trained model if available\n",
        "RUN_PRETRAINING = True\n",
        "pretrain_model_filename = f\"CAE_Pretrained_Epochs{CONFIG['PRETRAIN_EPOCHS']}_LR{CONFIG['PRETRAIN_LR']}.pth\"\n",
        "pretrain_model_path = os.path.join(CONFIG[\"OUTPUT_DIR\"], pretrain_model_filename)\n",
        "\n",
        "initial_centroids_filename = f\"InitialCentroids_KMeans.npy\"\n",
        "initial_centroids_path = os.path.join(CONFIG[\"OUTPUT_DIR\"], initial_centroids_filename)\n",
        "\n",
        "\n",
        "if RUN_PRETRAINING or not os.path.exists(pretrain_model_path) or not os.path.exists(initial_centroids_path):\n",
        "    print(\"Running pre-training phase...\")\n",
        "    initial_centroids, saved_pretrain_path = pretrain_cae(cae_model, train_dl_pretrain, CONFIG, CONFIG[\"DEVICE\"])\n",
        "    pretrain_model_path = saved_pretrain_path # Update path if it was just saved\n",
        "else:\n",
        "    print(f\"Skipping pre-training. Loading pre-trained model from {pretrain_model_path} and centroids from {initial_centroids_path}\")\n",
        "    # Model state will be loaded in train_auec, just need centroids here\n",
        "    initial_centroids = torch.from_numpy(np.load(initial_centroids_path)).float().to(CONFIG[\"DEVICE\"])\n",
        "\n",
        "# 4. Stage I: AUEC Training\n",
        "RUN_AUEC_TRAINING = True\n",
        "auec_model_filename = f\"AUEC_Model_Final_Epochs{CONFIG['AUEC_EPOCHS']}.pth\"\n",
        "auec_model_path = os.path.join(CONFIG[\"OUTPUT_DIR\"], auec_model_filename)\n",
        "\n",
        "if RUN_AUEC_TRAINING or not os.path.exists(auec_model_path):\n",
        "    print(\"Running AUEC training phase...\")\n",
        "    # Pass pretrain_model_path so AUEC training can load the weights\n",
        "    final_auec_model_path, final_centroids = train_auec(cae_model, train_dl_auec, initial_centroids, CONFIG, CONFIG[\"DEVICE\"], pretrained_model_path=pretrain_model_path)\n",
        "    auec_model_path = final_auec_model_path # Update path\n",
        "else:\n",
        "    print(f\"Skipping AUEC training. Assuming final model exists at {auec_model_path}\")\n",
        "    # If not training, embeddings need to be loaded or generated from this model\n",
        "    # For simplicity, we'll assume if AUEC training is skipped, embeddings also exist or will be generated next.\n",
        "\n",
        "# 5. Evaluation: Get Embeddings from AUEC Model\n",
        "# We always get embeddings after AUEC training or if loading a pre-existing AUEC model\n",
        "compressed_embeddings_path = os.path.join(CONFIG[\"OUTPUT_DIR\"], \"AUEC_CompressedEmbeddings.npy\")\n",
        "if RUN_AUEC_TRAINING or not os.path.exists(compressed_embeddings_path): # Generate if AUEC was run or if file doesn't exist\n",
        "      compressed_embedding = get_embeddings(cae_model, full_train_dl, CONFIG, CONFIG[\"DEVICE\"], model_path=auec_model_path)\n",
        "else:\n",
        "    print(f\"Loading existing compressed embeddings from {compressed_embeddings_path}\")\n",
        "    compressed_embedding = np.load(compressed_embeddings_path)\n",
        "\n",
        "\n",
        "# 6. Stage II: UMAP\n",
        "refined_embeddings_path = os.path.join(CONFIG[\"OUTPUT_DIR\"], f\"UMAP_RefinedEmbeddings_NComp{CONFIG['UMAP_N_COMPONENTS']}_NNeigh{CONFIG['UMAP_N_NEIGHBORS']}.npy\")\n",
        "# Always run UMAP if embeddings were just generated, or if refined embeddings don't exist\n",
        "if RUN_AUEC_TRAINING or not os.path.exists(refined_embeddings_path) or not os.path.exists(compressed_embeddings_path): # Added check for compressed_embeddings_path for safety\n",
        "    refined_embedding = apply_umap(compressed_embedding, CONFIG)\n",
        "else:\n",
        "    print(f\"Loading existing UMAP refined embeddings from {refined_embeddings_path}\")\n",
        "    refined_embedding = np.load(refined_embeddings_path)\n",
        "\n",
        "# Plot true labels on UMAP embedding\n",
        "if refined_embedding.shape[1] == 2:\n",
        "    true_labels_plot_path = os.path.join(CONFIG[\"OUTPUT_DIR\"], \"UMAP_TrueLabels_Plot.png\")\n",
        "    plot_embedding_space(refined_embedding, train_true_labels, \"UMAP Embedding with True Labels\", true_labels_plot_path, CONFIG)\n",
        "\n",
        "# 7. Stage III: Clustering\n",
        "# K-Means\n",
        "kmeans_results = run_kmeans_clustering(refined_embedding, train_true_labels, CONFIG)\n",
        "\n",
        "# MDBSCAN\n",
        "mdbscan_results = run_mdbscan_clustering(refined_embedding, train_true_labels, CONFIG)\n",
        "\n",
        "print(\"\\n--- All Stages Complete ---\")\n",
        "print(\"K-Means Results:\", kmeans_results)\n",
        "print(\"MDBSCAN Results:\", mdbscan_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KUPLroGlD1Q",
        "outputId": "cb9dec01-8621-458d-d12a-880451c7cbfd"
      },
      "id": "4KUPLroGlD1Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seeded everything with seed 42\n",
            "Created directory: ./drive/MyDrive/output/\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.09MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 135kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.59MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST training data: 60000 samples\n",
            "MNIST test data: 10000 samples\n",
            "Running pre-training phase...\n",
            "\n",
            "--- Starting CAE Pre-training ---\n",
            "Pre-train Epoch: 1/10\tTraining Loss: 0.041054\n",
            "Pre-train Epoch: 2/10\tTraining Loss: 0.012996\n",
            "Pre-train Epoch: 3/10\tTraining Loss: 0.011119\n",
            "Pre-train Epoch: 4/10\tTraining Loss: 0.010500\n",
            "Pre-train Epoch: 5/10\tTraining Loss: 0.010015\n",
            "Pre-train Epoch: 6/10\tTraining Loss: 0.009779\n",
            "Pre-train Epoch: 7/10\tTraining Loss: 0.009533\n",
            "Pre-train Epoch: 8/10\tTraining Loss: 0.009383\n",
            "Pre-train Epoch: 9/10\tTraining Loss: 0.009362\n",
            "Pre-train Epoch: 10/10\tTraining Loss: 0.009196\n",
            "Saved pre-trained model to ./drive/MyDrive/output/CAE_Pretrained_Epochs10_LR0.01.pth\n",
            "Applying KMeans to pre-trained embeddings for initial centroids...\n",
            "Saved initial K-Means centroids to ./drive/MyDrive/output/InitialCentroids_KMeans.npy\n",
            "Running AUEC training phase...\n",
            "\n",
            "--- Starting AUEC Training (Stage I) ---\n",
            "Loading pre-trained weights from: ./drive/MyDrive/output/CAE_Pretrained_Epochs10_LR0.01.pth\n",
            "AUEC Epoch: 1/10 \tTotal Loss: 0.011071 \tRecon Loss: 0.010486 \tCluster Loss: 0.000585\n",
            "AUEC Epoch: 2/10 \tTotal Loss: 0.008528 \tRecon Loss: 0.008385 \tCluster Loss: 0.000143\n",
            "AUEC Epoch: 3/10 \tTotal Loss: 0.008207 \tRecon Loss: 0.008095 \tCluster Loss: 0.000112\n",
            "AUEC Epoch: 4/10 \tTotal Loss: 0.008166 \tRecon Loss: 0.008064 \tCluster Loss: 0.000101\n",
            "AUEC Epoch: 5/10 \tTotal Loss: 0.008044 \tRecon Loss: 0.007950 \tCluster Loss: 0.000094\n",
            "AUEC Epoch: 6/10 \tTotal Loss: 0.008033 \tRecon Loss: 0.007941 \tCluster Loss: 0.000091\n",
            "AUEC Epoch: 7/10 \tTotal Loss: 0.007993 \tRecon Loss: 0.007904 \tCluster Loss: 0.000088\n",
            "AUEC Epoch: 8/10 \tTotal Loss: 0.007943 \tRecon Loss: 0.007856 \tCluster Loss: 0.000086\n",
            "AUEC Epoch: 9/10 \tTotal Loss: 0.007913 \tRecon Loss: 0.007829 \tCluster Loss: 0.000084\n",
            "AUEC Epoch: 10/10 \tTotal Loss: 0.007974 \tRecon Loss: 0.007888 \tCluster Loss: 0.000086\n",
            "Saved AUEC loss curve to ./drive/MyDrive/output/AUEC_LossCurve_Epochs10_RW1.0_SW0.0003.png\n",
            "Saved final AUEC model to ./drive/MyDrive/output/AUEC_Model_Final_Epochs10.pth\n",
            "\n",
            "--- Extracting Embeddings ---\n",
            "Loading model for embedding extraction from: ./drive/MyDrive/output/AUEC_Model_Final_Epochs10.pth\n",
            "Saved compressed embeddings ((60000, 64)) to ./drive/MyDrive/output/AUEC_CompressedEmbeddings.npy\n",
            "\n",
            "--- Applying UMAP (Stage II) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved UMAP refined embeddings ((60000, 8)) to ./drive/MyDrive/output/UMAP_RefinedEmbeddings_NComp8_NNeigh8.npy\n",
            "\n",
            "--- Running K-Means Clustering (Stage III) ---\n",
            "Saved K-Means mapped predicted labels to ./drive/MyDrive/output/KMeans_PredictedLabels_Mapped.npy\n",
            "\n",
            "--- K-Means Clustering Results ---\n",
            "Accuracy (ACC): 0.9751\n",
            "Normalized Mutual Information (NMI): 0.9353\n",
            "Adjusted Rand Index (ARI): 0.9459\n",
            "\n",
            "--- Running MDBSCAN Clustering (Stage III) ---\n",
            "DBSCAN initial clusters found: Counter({np.int64(3): 6487, np.int64(4): 5975, np.int64(6): 5972, np.int64(1): 5916, np.int64(7): 5873, np.int64(5): 5872, np.int64(9): 5778, np.int64(2): 5635, np.int64(8): 5468, np.int64(0): 5303, np.int64(-1): 765, np.int64(10): 685, np.int64(11): 49, np.int64(12): 25, np.int64(18): 25, np.int64(16): 22, np.int64(14): 21, np.int64(23): 19, np.int64(21): 17, np.int64(20): 15, np.int64(24): 14, np.int64(22): 14, np.int64(13): 13, np.int64(15): 13, np.int64(17): 12, np.int64(19): 12})\n",
            "MDBSCAN: Top 10 largest non-noise clusters selected: [np.int64(3), np.int64(4), np.int64(6), np.int64(1), np.int64(7), np.int64(5), np.int64(9), np.int64(2), np.int64(8), np.int64(0)]\n",
            "Saved MDBSCAN mapped predicted labels to ./drive/MyDrive/output/MDBSCAN_PredictedLabels_Mapped.npy\n",
            "\n",
            "--- MDBSCAN Clustering Results ---\n",
            "Accuracy (ACC): 0.9751\n",
            "Normalized Mutual Information (NMI): 0.9353\n",
            "Adjusted Rand Index (ARI): 0.9459\n",
            "\n",
            "--- All Stages Complete ---\n",
            "K-Means Results: {'ACC': 0.9751, 'NMI': np.float64(0.9352735266712181), 'ARI': 0.9459038070858824}\n",
            "MDBSCAN Results: {'ACC': 0.9751, 'NMI': np.float64(0.9352690520993595), 'ARI': 0.9459040342729622}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "erZXjwTSh-OY",
        "8c47fb4f",
        "vV75ue4-iskD",
        "b0b7db33",
        "03eb27ed",
        "46347963",
        "e96748f6",
        "7964c79c",
        "797e4158",
        "1e9a6078",
        "f678b74f",
        "1I_-1Qp2k_IF"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}